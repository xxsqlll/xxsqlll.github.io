<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"xxsqlll.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"always","padding":18,"offset":12,"onmobile":false,"b2t":true,"scrollpercent":true},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="多重线性回归1. 应用场景在日常生活中，通常是多个因素导致了结果。像这种，多个自变量共同影响一个因变量的情况，我们会应用多重线性回归。 2. STEP 1 绘制散点图，确定相关系数 matplotlib中的scatter()函数，可以实现绘制单个散点图，但绘制多个太过麻烦。 而Python中的另一个模块seaborn，可以非常简便的绘制多组图像，在回归模型中应用很多。">
<meta property="og:type" content="article">
<meta property="og:title" content="多重线性回归">
<meta property="og:url" content="https://xxsqlll.github.io/posts/23702362/index.html">
<meta property="og:site_name" content="小刑的博客">
<meta property="og:description" content="多重线性回归1. 应用场景在日常生活中，通常是多个因素导致了结果。像这种，多个自变量共同影响一个因变量的情况，我们会应用多重线性回归。 2. STEP 1 绘制散点图，确定相关系数 matplotlib中的scatter()函数，可以实现绘制单个散点图，但绘制多个太过麻烦。 而Python中的另一个模块seaborn，可以非常简便的绘制多组图像，在回归模型中应用很多。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://nocturne.bczcdn.com/9a7cf248-55d6-11ee-98d2-0242ac11002f/figure_1.png">
<meta property="og:image" content="https://nocturne.bczcdn.com/437a9d54-55d8-11ee-abc7-0242ac110012/figure_1.png">
<meta property="og:image" content="http://nocturne.bczcdn.com/img/1644974366086_98003/%E5%85%B1%E7%BA%BF%E6%80%A7.png">
<meta property="og:image" content="http://nocturne.bczcdn.com/img/1645091260276_67608/hot-42.png">
<meta property="article:published_time" content="2023-09-18T12:29:45.000Z">
<meta property="article:modified_time" content="2023-09-18T12:29:47.625Z">
<meta property="article:author" content="小刑">
<meta property="article:tag" content="学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://nocturne.bczcdn.com/9a7cf248-55d6-11ee-98d2-0242ac11002f/figure_1.png">

<link rel="canonical" href="https://xxsqlll.github.io/posts/23702362/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>多重线性回归 | 小刑的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="小刑的博客" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">小刑的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">五马六猴，解衣磅礴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-movies">

    <a href="/movies/" rel="section"><i class="fa fa-film fa-fw"></i>电影</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/xxsqlll" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xxsqlll.github.io/posts/23702362/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.JPG">
      <meta itemprop="name" content="小刑">
      <meta itemprop="description" content="这个人很懒，什么也不想写">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小刑的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          多重线性回归
        </h1>

        <div class="post-meta">
          <span class="post-time">

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-09-18 20:29:45 / 修改时间：20:29:47" itemprop="dateCreated datePublished" datetime="2023-09-18T20:29:45+08:00">2023-09-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          
            <span id="/posts/23702362/" class="post-meta-item leancloud_visitors" data-flag-title="多重线性回归" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
          <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
              <i class="fa fa-fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
          </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/posts/23702362/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/posts/23702362/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>19 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="多重线性回归"><a href="#多重线性回归" class="headerlink" title="多重线性回归"></a>多重线性回归</h1><h2 id="1-应用场景"><a href="#1-应用场景" class="headerlink" title="1. 应用场景"></a>1. 应用场景</h2><p>在日常生活中，通常是多个因素导致了结果。像这种，多个自变量共同影响一个因变量的情况，我们会应用多重线性回归。</p>
<h2 id="2-STEP-1-绘制散点图，确定相关系数"><a href="#2-STEP-1-绘制散点图，确定相关系数" class="headerlink" title="2. STEP 1 绘制散点图，确定相关系数"></a>2. STEP 1 绘制散点图，确定相关系数</h2><blockquote>
<p>matplotlib中的<code>scatter()</code>函数，可以实现绘制单个散点图，但绘制多个太过麻烦。</p>
<p>而Python中的另一个模块<code>seaborn</code>，可以非常简便的绘制多组图像，在回归模型中应用很多。</p>
</blockquote>
<h3 id="多变量散点图"><a href="#多变量散点图" class="headerlink" title="多变量散点图"></a>多变量散点图</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装seaborn模块</span></span><br><span class="line">pip install seaborn</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入seaborn模块，简称为sns</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 通过调用seaborn模块里的pairplot()函数，可以画出数据两两之间的特征图像。</span></span><br><span class="line">sns.pairplot(df)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://nocturne.bczcdn.com/9a7cf248-55d6-11ee-98d2-0242ac11002f/figure_1.png" style="zoom: 40%;" />

<blockquote>
<p>这张5*5的多变量散点图，描绘的就是数据集中的5个字段两两之间的关系</p>
</blockquote>
<h3 id="相关系数热力图"><a href="#相关系数热力图" class="headerlink" title="相关系数热力图"></a>相关系数热力图</h3><p>通过<code>corr()</code>函数得到相关系数矩阵后。</p>
<p>使用seaborn模块中<code>heatmap()</code>函数对相关系数矩阵进行可视化，绘制相关系数热力图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">corr = df.corr()</span><br><span class="line"><span class="comment"># 使用sns的heatmap函数，绘制相关系数热力图</span></span><br><span class="line"><span class="comment"># 参数一：用于指定绘图的数据</span></span><br><span class="line"><span class="comment"># 参数二：用于设置颜色，&quot;RdBn&quot;表示红蓝色</span></span><br><span class="line"><span class="comment"># 参数三：表示是否是热力图的每个单元格为正方形，默认为False</span></span><br><span class="line"><span class="comment"># 参数四：表示是否在每个单元格上显示数据</span></span><br><span class="line">sns.heatmap(corr,cmap=<span class="string">&quot;RdBu&quot;</span>,square=<span class="literal">True</span>,annot=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://nocturne.bczcdn.com/437a9d54-55d8-11ee-abc7-0242ac110012/figure_1.png" style="zoom:70%;" />

<blockquote>
<p>最右边的图例，表示不同数值所对应的颜色。</p>
<p>图表中，相应的计算结果，都会展示所对应的颜色。</p>
<p>蓝色，表示两个值是正相关；</p>
<p>红色，表示两个值是负相关。</p>
<p>颜色的深浅表示相关程度，颜色<strong>越深越相关</strong>，颜色越浅越不相关。</p>
</blockquote>
<hr>
<h2 id="STEP-2-确定自变量和因变量"><a href="#STEP-2-确定自变量和因变量" class="headerlink" title="STEP 2 确定自变量和因变量"></a>STEP 2 确定自变量和因变量</h2><p>可以从上述热力图看出，”new_user”与”exposure”，”hot”，”search”三个变量呈正相关，所以可以确定自变量</p>
<hr>
<h2 id="STEP-3-建立回归模型"><a href="#STEP-3-建立回归模型" class="headerlink" title="STEP 3 建立回归模型"></a>STEP 3 建立回归模型</h2><p>一元线性回归和多重线性回归，在建模上的不同只是自变量从一个维度变成了多个维度，其他几乎一样。</p>
<p>类比一元线性回归。</p>
<p>这里有3个自变量，故多重线性回归模型可以表示为：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Y</span> = a + bX1 + cX2 + dX3</span><br></pre></td></tr></table></figure>

<p>其中<code>X1,X2,X3</code>为不同的自变量，<code>b,c,d</code>是对应的系数，a是截距。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">     exposure   hot  search</span><br><span class="line">0     <span class="number"> 150538 </span><span class="number"> 8370 </span>  16358</span><br><span class="line">1     <span class="number"> 198625 </span><span class="number"> 8561 </span>  21785</span><br><span class="line">2     <span class="number"> 189144 </span><span class="number"> 8464 </span>  18835</span><br><span class="line">3     <span class="number"> 157297 </span><span class="number"> 8352 </span>  15922</span><br><span class="line">4     <span class="number"> 143070 </span><span class="number"> 8370 </span>  16358</span><br><span class="line">..        ...   ...     ...</span><br><span class="line">116   <span class="number"> 117659 </span><span class="number"> 8483 </span>  19380</span><br><span class="line">117   <span class="number"> 119056 </span><span class="number"> 8363 </span>  16187</span><br><span class="line">118    <span class="number"> 94557 </span><span class="number"> 8419 </span>  17606</span><br><span class="line">119    <span class="number"> 99117 </span><span class="number"> 8349 </span>  15851</span><br><span class="line">120   <span class="number"> 108501 </span><span class="number"> 8350 </span>  15875</span><br><span class="line"></span><br><span class="line">[121 rows x<span class="number"> 3 </span>columns]</span><br><span class="line">     new_user</span><br><span class="line">0        2407</span><br><span class="line">1        2938</span><br><span class="line">2        2733</span><br><span class="line">3        2417</span><br><span class="line">4        2370</span><br><span class="line">..        ...</span><br><span class="line">116      2309</span><br><span class="line">117      2151</span><br><span class="line">118      2107</span><br><span class="line">119      2038</span><br><span class="line">120      2084</span><br><span class="line"></span><br><span class="line">[121 rows x<span class="number"> 1 </span>columns]</span><br></pre></td></tr></table></figure>

<h3 id="模型的初始化和训练"><a href="#模型的初始化和训练" class="headerlink" title="模型的初始化和训练"></a>模型的初始化和训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line">b = lr_model.coef_[<span class="number">0</span>][<span class="number">0</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">c = lr_model.coef_[<span class="number">0</span>][<span class="number">1</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">d = lr_model.coef_[<span class="number">0</span>][<span class="number">2</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">a = lr_model.intercept_[<span class="number">0</span>].<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;该线性回归模型：Y=a+<span class="subst">&#123;b&#125;</span>X1+<span class="subst">&#123;c&#125;</span>X2+<span class="subst">&#123;d&#125;</span>X3&quot;</span>)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">该线性回归模型为：Y=<span class="string">-7004</span>.53<span class="string">+0</span>.0049X1<span class="string">+1</span>.0058X2<span class="string">+0</span>.0132X3</span><br></pre></td></tr></table></figure>



<h2 id="STEP-4-检验回归模型"><a href="#STEP-4-检验回归模型" class="headerlink" title="STEP 4 检验回归模型"></a>STEP 4 检验回归模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以二维结构读取&quot;exposure&quot;,&quot;hot&quot;,&quot;search&quot;这三列，作为自变量x</span></span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>, <span class="string">&quot;hot&quot;</span>, <span class="string">&quot;search&quot;</span>]]</span><br><span class="line"><span class="comment"># 以二维结构读取&quot;new_user&quot;，作为因变量y</span></span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入sklearn.linear_model模块中的LinearRegression函数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用LinearRegression()初始化模型，赋值给lr_model</span></span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line"><span class="comment"># 使用lr_model模型的fit()函数，训练模型</span></span><br><span class="line">lr_model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将x,y传入score( )函数，对模型打分,获取判定系数r2</span></span><br><span class="line">r2 = lr_model.score(x,y)</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.9437117881084567</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>判定系数为<code>0.94</code>，非常接近1，模型精度足够高，我们可以用它进行简单的预测。</p>
</blockquote>
<hr>
<h2 id="STEP-5-利用模型预测"><a href="#STEP-5-利用模型预测" class="headerlink" title="STEP 5 利用模型预测"></a>STEP 5 利用模型预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以二维结构读取&quot;exposure&quot;,&quot;hot&quot;,&quot;search&quot;这三列，作为自变量x</span></span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>, <span class="string">&quot;hot&quot;</span>, <span class="string">&quot;search&quot;</span>]]</span><br><span class="line"><span class="comment"># 以二维结构读取&quot;new_user&quot;，作为因变量y</span></span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入sklearn.linear_model模块中的LinearRegression函数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用LinearRegression()初始化模型，赋值给lr_model</span></span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line"><span class="comment"># 使用lr_model模型的fit()函数，训练模型</span></span><br><span class="line">lr_model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 曝光量，搜索热度，关键词搜索量依次为300000,10000,30000</span></span><br><span class="line"><span class="comment"># 将300000,10000,30000以二维结构传入传入predict()函数进行预测，并赋值给 y_predict</span></span><br><span class="line">y_predict = lr_model.predict([[<span class="number">300000</span>,<span class="number">10000</span>,<span class="number">30000</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出预测结果y_predict</span></span><br><span class="line"><span class="built_in">print</span>(y_predict)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[[4907.73763213]]</span></span><br></pre></td></tr></table></figure>

<hr>
<h1 id="多重共线性的判断"><a href="#多重共线性的判断" class="headerlink" title="多重共线性的判断"></a>多重共线性的判断</h1><p>简单来说，不同自变量之间存在高度的线性相关关系，就会导致多重共线性问题。</p>
<p>关于多重共线性有两种判别方法： <strong>相关系数判断</strong> 、 <strong>方差膨胀系数法</strong> 。</p>
<h2 id="1-相关系数判断"><a href="#1-相关系数判断" class="headerlink" title="1. 相关系数判断"></a>1. 相关系数判断</h2><p>对 exposure、hot、search这几个变量之间进行corr查看相关系数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="built_in">print</span>(x.corr()) </span><br></pre></td></tr></table></figure>



<p><strong>ouput:</strong></p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">         <span class="attribute">exposure</span>       hot    search</span><br><span class="line"><span class="attribute">exposure</span>  <span class="number">1</span>.<span class="number">000000</span>  <span class="number">0</span>.<span class="number">516877</span>  <span class="number">0</span>.<span class="number">507091</span></span><br><span class="line"><span class="attribute">hot</span>       <span class="number">0</span>.<span class="number">516877</span>  <span class="number">1</span>.<span class="number">000000</span>  <span class="number">0</span>.<span class="number">993623</span></span><br><span class="line"><span class="attribute">search</span>    <span class="number">0</span>.<span class="number">507091</span>  <span class="number">0</span>.<span class="number">993623</span>  <span class="number">1</span>.<span class="number">000000</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以看到，search和hot之间有严重的多重共线性。</p>
<p>不过相关系数只是多重线性的充分条件不是必要条件。</p>
<p>但是相关系数太小时，也可能存在较为严重的多重共线性。比如exposure和hot以及exposure和search。</p>
<p>此时可以使用方差膨胀系数来进一步确定多重共线性的关系。</p>
</blockquote>
<h2 id="2-方差膨胀系数"><a href="#2-方差膨胀系数" class="headerlink" title="2. 方差膨胀系数"></a>2. 方差膨胀系数</h2><p>方差膨胀系数法，简称VIF检验<br><strong>VIF检验</strong>是﻿用于衡量多重线性回归模型中，多重共线性严重程度的一种度量</p>
<p>Python中的<code>Statsmodels</code>库提供了计算VIF值的函数，我们可以直接导入使用。</p>
<h3 id="2-1-导入variance-inflation-factor函数"><a href="#2-1-导入variance-inflation-factor函数" class="headerlink" title="2.1 导入variance_inflation_factor函数"></a>2.1 导入variance_inflation_factor函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">from</span> statsmodels.stats.outliers_influence <span class="keyword">import</span> variance_inflation_factor</span><br><span class="line"><span class="comment"># 通过variance_inflation_factor()函数，结合for循环依次求得自变量间的方差膨胀系数，并将结果放入列表中，赋值给变量vif。</span></span><br><span class="line"><span class="comment"># x.values作为自变量传入</span></span><br><span class="line"><span class="comment"># x.columns.get_loc(i)表示返回i所在列的索引。如，第1列，返回数字0；第2列，返回数字1，以此类推。</span></span><br><span class="line"><span class="comment"># 这里的i所在列，即自变量&quot;exposure&quot;, &quot;hot&quot;, &quot;search&quot;所在的列，依次返回0,1,2。</span></span><br><span class="line"><span class="comment"># 中括号表示将求得的方差膨胀系数的结果放入列表</span></span><br><span class="line">vif = [variance_inflation_factor(x.values,x.columns.get_loc(i)) <span class="keyword">for</span> i <span class="keyword">in</span> x.columns]</span><br><span class="line"><span class="built_in">print</span>(vif)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[32.31907643878631, 136.9115541589221, 176.7628569694301]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>VIF值的大小表示一个自变量与其余自变量之间，共线的严重程度</p>
</blockquote>
<img src="http://nocturne.bczcdn.com/img/1644974366086_98003/%E5%85%B1%E7%BA%BF%E6%80%A7.png" style="zoom:25%;" />

<blockquote>
<p>也就是说，自变量<code>hot, search</code>的VIF值均大于100，说明多重共线性十分严重，需要进行处理。</p>
<p>如果还是利用全部数据集，来处理多重共线性，模型很容易出现：过拟合（模型对数据集的拟合程度过高，但是对数据集外的数据达不到较好的效果）。我们可以先通过把数据集划分的方式，来处理过拟合的问题</p>
</blockquote>
<hr>
<h1 id="划分训练集和测试集"><a href="#划分训练集和测试集" class="headerlink" title="划分训练集和测试集"></a>划分训练集和测试集</h1><h2 id="1-导入train-test-split-函数"><a href="#1-导入train-test-split-函数" class="headerlink" title="1. 导入train_test_split()函数"></a>1. 导入train_test_split()函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>, <span class="string">&quot;hot&quot;</span>, <span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment"># 导入train_test_split()函数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 使用train_test_split()函数划分训练集和测试集，设置参数test_size=0.2，random_state=1</span></span><br><span class="line"><span class="comment"># 依次赋值给x_train,x_test,y_train,y_test</span></span><br><span class="line"><span class="comment"># x,y作为自变量和因变量传入，等待被划分</span></span><br><span class="line"><span class="comment"># test_size用于设置测试集所占的比例，这里选择0.2，即20%</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1</span>)</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line">lr_model.fit(x_train,y_train)</span><br><span class="line"><span class="built_in">print</span>(lr_model.score(x_test,y_test))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>通过设置参数<code>random_state</code>可以保证程序每次运行都分割一样的训练集和测试集。</p>
<p><code>random_state=1</code>的数<code>1</code>没有特殊含义，可以是其他数字。</p>
<p>也就是说<code>random_state=2</code>和<code>random_state=1</code>划分的训练集和测试集是不一样的。</p>
</blockquote>
<p><strong>output:</strong></p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">     exposure   hot  search</span><br><span class="line">97    <span class="number"> 164539 </span><span class="number"> 8342 </span>  15685</span><br><span class="line">35    <span class="number"> 143070 </span><span class="number"> 8370 </span>  16358</span><br><span class="line">44    <span class="number"> 116186 </span><span class="number"> 8296 </span>  15639</span><br><span class="line">93    <span class="number"> 189144 </span><span class="number"> 8464 </span>  18835</span><br><span class="line">115   <span class="number"> 149406 </span><span class="number"> 8497 </span>  19791</span><br><span class="line">..        ...   ...     ...</span><br><span class="line">9     <span class="number"> 167707 </span><span class="number"> 8418 </span>  17579</span><br><span class="line">72     <span class="number"> 89742 </span><span class="number"> 8316 </span>  15285</span><br><span class="line">12     <span class="number"> 89742 </span><span class="number"> 8316 </span>  15085</span><br><span class="line">107   <span class="number"> 169099 </span><span class="number"> 8398 </span>  17060</span><br><span class="line">37    <span class="number"> 164539 </span><span class="number"> 8342 </span>  15685</span><br><span class="line"></span><br><span class="line">[96 rows x<span class="number"> 3 </span>columns]</span><br><span class="line">     new_user</span><br><span class="line">97       2343</span><br><span class="line">35       2275</span><br><span class="line">44       2056</span><br><span class="line">93       2624</span><br><span class="line">115      2482</span><br><span class="line">..        ...</span><br><span class="line">9        2559</span><br><span class="line">72       2036</span><br><span class="line">12       2034</span><br><span class="line">107      2436</span><br><span class="line">37       2343</span><br><span class="line"></span><br><span class="line">[96 rows x<span class="number"> 1 </span>columns]</span><br></pre></td></tr></table></figure>

<h2 id="2-建立新的模型"><a href="#2-建立新的模型" class="headerlink" title="2. 建立新的模型"></a>2. 建立新的模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>, <span class="string">&quot;hot&quot;</span>, <span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 使用train_test_split()函数划分训练集和测试集，设置参数test_size=0.2，random_state=1</span></span><br><span class="line"><span class="comment"># 依次赋值给x_train,x_test,y_train,y_test</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1</span>)</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line">lr_model.fit(x_train,y_train)</span><br><span class="line">b = lr_model.coef_[<span class="number">0</span>][<span class="number">0</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">c = lr_model.coef_[<span class="number">0</span>][<span class="number">1</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">d = lr_model.coef_[<span class="number">0</span>][<span class="number">2</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">a = lr_model.intercept_[<span class="number">0</span>].<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 格式化输出，f&quot;线性回归模型为：Y=&#123;a&#125;+&#123;b&#125;X1+&#123;c&#125;X2+&#123;d&#125;X3&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;线性回归模型为：Y=<span class="subst">&#123;a&#125;</span>+<span class="subst">&#123;b&#125;</span>X1+<span class="subst">&#123;c&#125;</span>X2+<span class="subst">&#123;d&#125;</span>X3&quot;</span>)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">线性回归模型为：Y=<span class="string">-7723</span>.97<span class="string">+0</span>.0047X1<span class="string">+1</span>.0984X2<span class="string">+0</span>.0114X3</span><br></pre></td></tr></table></figure>



<h2 id="3-测试集来对模型打分"><a href="#3-测试集来对模型打分" class="headerlink" title="3.测试集来对模型打分"></a>3.测试集来对模型打分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>, <span class="string">&quot;hot&quot;</span>, <span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1</span>)</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line"><span class="comment"># 使用score函数对模型进行打分</span></span><br><span class="line">r2 = lr_model.score(x_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">0</span>.<span class="number">9440294294613383</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>划分训练集和测试集，在某种程度上避免了模型的过拟合问题，加强了模型的泛化能力。</p>
<p>并且新模型的判定系数R方为0.94，精度依然很高</p>
<p>接着，处理多重线性回归问题</p>
</blockquote>
<hr>
<h1 id="手动移除自变量（处理多重线性回归）"><a href="#手动移除自变量（处理多重线性回归）" class="headerlink" title="手动移除自变量（处理多重线性回归）"></a>手动移除自变量（处理多重线性回归）</h1><p>由上述代码结果显示，hot和search的VIF都很大，不能单纯通过数值的大小移除其中的某个自变量，可以尝试分别移除两个变量</p>
<h2 id="1-移除hot"><a href="#1-移除hot" class="headerlink" title="1. 移除hot"></a>1. 移除hot</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">from</span> statsmodel.stats.outliers_influence <span class="keyword">import</span> variance_inflating_factor</span><br><span class="line">x = x.drop(columns=<span class="string">&quot;hot&quot;</span>)</span><br><span class="line">vif = [variance_inflating_factor(x.values,x.columns.get_loc(i)) <span class="keyword">for</span> i <span class="keyword">in</span> x.columns]</span><br><span class="line"><span class="built_in">print</span>(vif)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[32.18058990784746, 32.18058990784746]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>移除<code>hot</code>后，剩下<code>exposure，search</code>2个自变量的VIF值都是32，没有超过100。</p>
<p>由于自变量太少，可以暂时不处理较强的多重共线性了。</p>
</blockquote>
<h2 id="2-移除search"><a href="#2-移除search" class="headerlink" title="2. 移除search"></a>2. 移除search</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">from</span> statsmodel.stats.outliers_influence <span class="keyword">import</span> variance_inflating_factor</span><br><span class="line">x = x.drop(columns=<span class="string">&quot;search&quot;</span>)</span><br><span class="line">vif = [variance_inflating_factor(x.values,x.columns.get_loc(i)) <span class="keyword">for</span> i <span class="keyword">in</span> x.columns]</span><br><span class="line"><span class="built_in">print</span>(vif)</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[24.92545466605748, 24.92545466605748]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>移除<code>search</code>后，剩下<code>exposure，hot</code>2个自变量的VIF值都是24，也没有超过100。</p>
<p>同样地，暂时不用继续处理。</p>
</blockquote>
<hr>
<h1 id="多重共线性的影响"><a href="#多重共线性的影响" class="headerlink" title="多重共线性的影响"></a>多重共线性的影响</h1><h2 id="1-判定系数的影响"><a href="#1-判定系数的影响" class="headerlink" title="1. 判定系数的影响"></a>1. 判定系数的影响</h2><p>严重的多重共线性，通常会对<strong>判定系数</strong>、系数或<strong>截距</strong>两个方面产生影响。</p>
<p>只需要查看，处理模型前后，这2个维度是否有较好的改变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]:</span><br><span class="line">    xi = x.drop(columns=i)</span><br><span class="line">    <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">    x_train,x_test,y_train,y_test = train_test_split(xi.values,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">    lr_model = LinearRgression()</span><br><span class="line">    lr_model.fit(x_train,y_train)</span><br><span class="line">    <span class="built_in">print</span>(lr_model.score(x_test,y_test))</span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">0</span>.<span class="number">9448092382534743</span></span><br><span class="line"><span class="attribute">0</span>.<span class="number">943877187389806</span></span><br></pre></td></tr></table></figure>



<img src="http://nocturne.bczcdn.com/img/1645091260276_67608/hot-42.png" style="zoom:30%;" />

<blockquote>
<p>我们在前面计算了原始自变量时，模型的判定系数R方为<code>0.9440</code>，精度很高。</p>
<p>如图，当我们移除<code>hot</code>这个自变量时，判定系数有小幅<strong>上升</strong>。</p>
<p>当我们移除<code>search</code>这个自变量时，判定系数有小幅<strong>下降</strong>。</p>
</blockquote>
<p>也就是说，从判定系数这个维度，多重共线性对模型的影响不大，就算我们不移除自变量，模型也能够进行准确的预测。</p>
<h2 id="2-截距的影响"><a href="#2-截距的影响" class="headerlink" title="2. 截距的影响"></a>2. 截距的影响</h2><p>在上文中，使用原始自变量建立的模型是Y&#x3D;-7723.97+0.0047X1+1.0984X2+0.0114X3，而此时当三个自变量均为0时，new_user&#x3D;-7723.97，这明显与实际不符。</p>
<p>接下来查看移除自变量后对截距的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;/Users/mul/multiple_to_new.csv&quot;</span>)</span><br><span class="line">x = df[[<span class="string">&quot;exposure&quot;</span>,<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]]</span><br><span class="line">y = df[[<span class="string">&quot;new_user&quot;</span>]]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="string">&quot;hot&quot;</span>,<span class="string">&quot;search&quot;</span>]:</span><br><span class="line">    xi = x.drop(columns=i)</span><br><span class="line">    <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">    x_train,x_test,y_train,y_test = train_test_split(xi.values,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">    lr_model = LinearRgression()</span><br><span class="line">    lr_model.fit(x_train,y_train)</span><br><span class="line">    b = lr_model.coef_[<span class="number">0</span>][<span class="number">0</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">    c = lr_model.coef_[<span class="number">0</span>][<span class="number">1</span>].<span class="built_in">round</span>(<span class="number">4</span>)</span><br><span class="line">    a = lr_model.intercept_[<span class="number">0</span>].<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;当自变量为<span class="subst">&#123;xi.columns.values&#125;</span>时:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;对应的线性回归模型为：<span class="subst">&#123;Y=a+&#123;b&#125;</span>X1+<span class="subst">&#123;c&#125;</span>X2&#125;&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>output:</strong></p>
<figure class="highlight tp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">自变量为[<span class="string">&#x27;exposure&#x27;</span> <span class="string">&#x27;search&#x27;</span>]时:</span><br><span class="line">对应的线性回归模型为：<span class="keyword">Y</span>=<span class="number">741</span><span class="number">.84</span>+<span class="number">0</span><span class="number">.0047</span><span class="keyword">X</span><span class="number">1</span>+<span class="number">0</span><span class="number">.0553</span><span class="keyword">X</span><span class="number">2</span></span><br><span class="line">自变量为[<span class="string">&#x27;exposure&#x27;</span> <span class="string">&#x27;hot&#x27;</span>]时:</span><br><span class="line">对应的线性回归模型为：<span class="keyword">Y</span>=<span class="number">-9877.68</span>+<span class="number">0</span><span class="number">.0047</span><span class="keyword">X</span><span class="number">1</span>+<span class="number">1</span><span class="number">.3783</span><span class="keyword">X</span><span class="number">2</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>当移除hot时，模型的系数或截距的正负情况，比较符合实际情况。</p>
<p>但是，当移除search时，又出现截距异常的情况。</p>
<p>说明，search列的数据对因变量的价值较大，贸然删除会导致模型失真。</p>
</blockquote>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/28281e4/" rel="bookmark">一元线性回归</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/a1ff4487/" rel="bookmark">用户分层模型</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/posts/24cc6ca3/" rel="bookmark">基于物品的协同过滤</a></div>
    </li>
  </ul>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>小刑
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://xxsqlll.github.io/posts/23702362/" title="多重线性回归">https://xxsqlll.github.io/posts/23702362/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%AD%A6%E4%B9%A0/" rel="tag"># 学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/posts/28281e4/" rel="prev" title="一元线性回归">
      <i class="fa fa-chevron-left"></i> 一元线性回归
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  
    <div>
      <div>
  
    <div style="text-align:center;color:#bfbfbf;font-size:16px;">
      <span>-------- 本文结束 </span>
      <i class="fa fa-paw"></i>
      <span> 感谢阅读 --------</span>
    </div>
  
</div>

    </div>
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E9%87%8D%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.</span> <span class="nav-text">多重线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.1.</span> <span class="nav-text">1. 应用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-STEP-1-%E7%BB%98%E5%88%B6%E6%95%A3%E7%82%B9%E5%9B%BE%EF%BC%8C%E7%A1%AE%E5%AE%9A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="nav-number">1.2.</span> <span class="nav-text">2. STEP 1 绘制散点图，确定相关系数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%8F%98%E9%87%8F%E6%95%A3%E7%82%B9%E5%9B%BE"><span class="nav-number">1.2.1.</span> <span class="nav-text">多变量散点图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%83%AD%E5%8A%9B%E5%9B%BE"><span class="nav-number">1.2.2.</span> <span class="nav-text">相关系数热力图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#STEP-2-%E7%A1%AE%E5%AE%9A%E8%87%AA%E5%8F%98%E9%87%8F%E5%92%8C%E5%9B%A0%E5%8F%98%E9%87%8F"><span class="nav-number">1.3.</span> <span class="nav-text">STEP 2 确定自变量和因变量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#STEP-3-%E5%BB%BA%E7%AB%8B%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.4.</span> <span class="nav-text">STEP 3 建立回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%92%8C%E8%AE%AD%E7%BB%83"><span class="nav-number">1.4.1.</span> <span class="nav-text">模型的初始化和训练</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#STEP-4-%E6%A3%80%E9%AA%8C%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.5.</span> <span class="nav-text">STEP 4 检验回归模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#STEP-5-%E5%88%A9%E7%94%A8%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="nav-number">1.6.</span> <span class="nav-text">STEP 5 利用模型预测</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E7%9A%84%E5%88%A4%E6%96%AD"><span class="nav-number">2.</span> <span class="nav-text">多重共线性的判断</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E5%88%A4%E6%96%AD"><span class="nav-number">2.1.</span> <span class="nav-text">1. 相关系数判断</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%96%B9%E5%B7%AE%E8%86%A8%E8%83%80%E7%B3%BB%E6%95%B0"><span class="nav-number">2.2.</span> <span class="nav-text">2. 方差膨胀系数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E5%AF%BC%E5%85%A5variance-inflation-factor%E5%87%BD%E6%95%B0"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.1 导入variance_inflation_factor函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="nav-number">3.</span> <span class="nav-text">划分训练集和测试集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%AF%BC%E5%85%A5train-test-split-%E5%87%BD%E6%95%B0"><span class="nav-number">3.1.</span> <span class="nav-text">1. 导入train_test_split()函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%BB%BA%E7%AB%8B%E6%96%B0%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.</span> <span class="nav-text">2. 建立新的模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E6%B5%8B%E8%AF%95%E9%9B%86%E6%9D%A5%E5%AF%B9%E6%A8%A1%E5%9E%8B%E6%89%93%E5%88%86"><span class="nav-number">3.3.</span> <span class="nav-text">3.测试集来对模型打分</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E7%A7%BB%E9%99%A4%E8%87%AA%E5%8F%98%E9%87%8F%EF%BC%88%E5%A4%84%E7%90%86%E5%A4%9A%E9%87%8D%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">手动移除自变量（处理多重线性回归）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E7%A7%BB%E9%99%A4hot"><span class="nav-number">4.1.</span> <span class="nav-text">1. 移除hot</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E7%A7%BB%E9%99%A4search"><span class="nav-number">4.2.</span> <span class="nav-text">2. 移除search</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">5.</span> <span class="nav-text">多重共线性的影响</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%88%A4%E5%AE%9A%E7%B3%BB%E6%95%B0%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">5.1.</span> <span class="nav-text">1. 判定系数的影响</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%88%AA%E8%B7%9D%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">5.2.</span> <span class="nav-text">2. 截距的影响</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="小刑"
      src="/images/avatar.JPG">
  <p class="site-author-name" itemprop="name">小刑</p>
  <div class="site-description" itemprop="description">这个人很懒，什么也不想写</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xxsqlll" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xxsqlll" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xxsqlll@gmail.com" title="E-Mail → mailto:xxsqlll@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



  <div class="links-of-recent-posts motion-element">
    <div class="links-of-recent-posts-title">
      <i class="fa fa-history fa-fw"></i>
      最近文章
    </div>
    <ul class="links-of-recent-posts-list">
        <li class="links-of-recent-posts-item">
          <a href="/posts/23702362/" title="posts&#x2F;23702362&#x2F;">多重线性回归</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/posts/28281e4/" title="posts&#x2F;28281e4&#x2F;">一元线性回归</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/posts/a1ff4487/" title="posts&#x2F;a1ff4487&#x2F;">用户分层模型</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/posts/24cc6ca3/" title="posts&#x2F;24cc6ca3&#x2F;">基于物品的协同过滤</a>
        </li>
        <li class="links-of-recent-posts-item">
          <a href="/posts/16d6d1f6/" title="posts&#x2F;16d6d1f6&#x2F;">关联分析和Apriori算法</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="music163player">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1831469103&auto=0&height=66">
      </iframe>
  </div>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小刑</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">163k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">4:56</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>--><div>
  <span id="sitetime"></span>
  <script language=javascript>
      function siteTime(){
          window.setTimeout("siteTime()", 1000);
          var seconds = 1000;
          var minutes = seconds * 60;
          var hours = minutes * 60;
          var days = hours * 24;
          var years = days * 365;
          var today = new Date();
          var todayYear = today.getFullYear();
          var todayMonth = today.getMonth()+1;
          var todayDate = today.getDate();
          var todayHour = today.getHours();
          var todayMinute = today.getMinutes();
          var todaySecond = today.getSeconds();
          /* 
          Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
          year - 作为date对象的年份，为4位年份值
          month - 0-11之间的整数，做为date对象的月份
          day - 1-31之间的整数，做为date对象的天数
          hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
          minutes - 0-59之间的整数，做为date对象的分钟数
          seconds - 0-59之间的整数，做为date对象的秒数
          microseconds - 0-999之间的整数，做为date对象的毫秒数
      */
          var t1 = Date.UTC(2023,7,18,11,40,00); //北京时间2018-2-13 00:00:00
          var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
          var diff = t2-t1;
      var diffYears = Math.floor(diff/years);
      var diffDays = Math.floor((diff/days)-diffYears*365);
      var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
      var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
      var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
      document.getElementById("sitetime").innerHTML=" 小破站已平稳运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
    }
      siteTime();
  </script>
</div>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
  <span class="site-uv" title="总访客量">
    我的第<span id="busuanzi_value_site_uv"></span>位朋友, 
  </span>

  <span class="site-pv" title="总访问量">
    经过<span id="busuanzi_value_site_pv"></span>次回眸与你相遇
  </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : '0VHq4jqwE0zTWM6rJFbms2tJ-gzGzoHsz',
      appKey     : '1QAGv9wIN4teXzpcIV8p6NyJ',
      placeholder: "欢迎交流",
      avatar     : 'monsterid',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

    </div>
  

  <script async src="/js/cursor/fireworks.js"></script>





  <canvas id="evanyou"></canvas>
  <style>
    #evanyou {
      position: fixed;
      width: 100%;
      height: 100%;
      top: 0;
      left: 0;
      z-index: -1;
    }
  </style>
  <script src="/js/evan-you.js"></script>



  
  
     <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
     <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
     <script type="text/javascript" src="/js/src/fireworks.js"></script>
  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>

